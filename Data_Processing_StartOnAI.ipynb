{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Processing - StartOnAI",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SD0313/StartOnAI/blob/master/Data_Processing_StartOnAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaQdyElQkhTw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from pandas.plotting import scatter_matrix\n",
        "import seaborn as sns\n",
        "from mpl_toolkits.mplot3d import Axes3D as ax\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS6KhPKGY02c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_subplots(df, cols, num = 5):\n",
        "  scatter_matrix(df[cols[:num]], figsize=(12, 8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqEk2Ikn83H7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def correlations(df, cols):\n",
        "  plt.figure(figsize=(16, 12))\n",
        "  imgs = sns.heatmap(df[cols].corr(), cmap=\"YlGnBu\", annot=True, fmt='.2f', vmin=0)\n",
        "  return imgs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHp2E3V10TES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(name, num_features=5, random_state=42, flatten=False, show_corr_matrix=True, show_subplots=True):\n",
        "  '''\n",
        "  Args:\n",
        "    name (str): name of dataset ('mnist', 'fmnist', 'iris', 'breast_cancer', 'diabetes', 'housing')\n",
        "    num_features (int): number of features to view in subplots, if None then num_features includes all features\n",
        "    random_state (int): specify random state\n",
        "    flatten (bool): returns image with shape (-1, 28, 28) if True, else returns image with shape (-1, 784)\n",
        "    show_corr_matrix (bool): whether to show correlation matrix\n",
        "    show_subplots (bool): whether to show subplots comparing the num_features\n",
        "\n",
        "  Returns:\n",
        "    (X_train, y_train): training data (numpy arrays)\n",
        "    (X_test, y_test): testing data (20% of total data)\n",
        "    col_names (list): feature names\n",
        "  '''\n",
        "\n",
        "  if name == 'mnist':\n",
        "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "    if flatten:\n",
        "      X_train = X_train.reshape(-1, 784)\n",
        "      X_test = X_test.reshape(-1, 784)\n",
        "    return (X_train, y_train), (X_test, y_test)\n",
        "\n",
        "  elif name == 'fashion_mnist' or name == 'fmnist':\n",
        "    (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "    if flatten:\n",
        "      X_train = X_train.reshape(-1, 784)\n",
        "      X_test = X_test.reshape(-1, 784)\n",
        "    return (X_train, y_train), (X_test, y_test)\n",
        "      \n",
        "  elif name == 'iris':\n",
        "    data = datasets.load_iris()\n",
        "    X = data.data\n",
        "    y = data.target\n",
        "    col_names = data.feature_names\n",
        "    df = pd.DataFrame(X, columns=col_names)\n",
        "    num = num_features\n",
        "    if num_features == None:\n",
        "      num = len(col_names)\n",
        "\n",
        "    if show_subplots:\n",
        "      img = plot_subplots(df, col_names, num)\n",
        "    if show_corr_matrix:\n",
        "      corr_img = correlations(df, col_names)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "  elif name == 'cancer' or name == 'breast_cancer':\n",
        "    data = datasets.load_breast_cancer()\n",
        "    X = data.data\n",
        "    y = data.target\n",
        "    col_names = data.feature_names\n",
        "    df = pd.DataFrame(X, columns=col_names)\n",
        "    num = num_features\n",
        "    if num_features == None:\n",
        "      num = len(col_names)\n",
        "   \n",
        "    if show_subplots:\n",
        "      img = plot_subplots(df, col_names, num)\n",
        "    if show_corr_matrix:\n",
        "      corr_img = correlations(df, col_names)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "  elif name == 'diabetes':\n",
        "    data = datasets.load_diabetes()\n",
        "    X = data.data\n",
        "    y = data.target\n",
        "    col_names = data.feature_names\n",
        "    df = pd.DataFrame(X, columns=col_names)\n",
        "    num = num_features\n",
        "    if num_features == None:\n",
        "      num = len(col_names)\n",
        "   \n",
        "    if show_subplots:\n",
        "      img = plot_subplots(df, col_names, num)\n",
        "    if show_corr_matrix:\n",
        "      corr_img = correlations(df, col_names)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "  elif name == 'house' or name == 'california_housing' or name == 'housing':\n",
        "    data = datasets.fetch_california_housing()\n",
        "    X = data.data\n",
        "    y = data.target\n",
        "    col_names = data.feature_names\n",
        "    df = pd.DataFrame(X, columns=col_names)\n",
        "    num = num_features\n",
        "    if num_features == None:\n",
        "      num = len(col_names)\n",
        "    if show_subplots:\n",
        "      img = plot_subplots(df, col_names, num)\n",
        "    if show_corr_matrix:\n",
        "      corr_img = correlations(df, col_names)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "  if show_corr_matrix:\n",
        "    plt.title(\"Correlation Matrix\")\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  return (X_train, y_train), (X_test, y_test), col_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRM42Vhc-XnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_custom(path, predicted_variable, num_features=5, random_state=42, show_corr_matrix = True, show_subplots=True):\n",
        "  '''\n",
        "  Args:\n",
        "    path(str): Path to the dataset \n",
        "    predicted_variable(str): The variable you are trying to get the output for\n",
        "    num_features(int): The number of features that you want to see on the Scatter_Matrix\n",
        "    random_state(int): Seed for the validation set(to be added)\n",
        "    show_corr_matrix(bool): If you want to see the correlation matrx or not\n",
        "    show_subplots(bool): If you want to see subplots or not\n",
        "\n",
        "  Returns:\n",
        "    data(dict): Containing X, and Y data\n",
        "    col_names(list): Contains a list of the column names\n",
        "\n",
        "\n",
        "  ''' \n",
        "\n",
        "  df = pd.read_csv(path)\n",
        "  X = df.drop(predicted_variable, axis=1)\n",
        "  y = df[predicted_variable]\n",
        "  col_names = X.columns\n",
        "  num = num_features\n",
        "  if num_features == None:\n",
        "    num = len(col_names)\n",
        "  \n",
        "  if show_subplots:\n",
        "    img = plot_subplots(df, col_names, num)\n",
        "\n",
        "  if show_corr_matrix:\n",
        "    corr_img = correlations(df, col_names)\n",
        "  \n",
        "  data = {\n",
        "      \"X\" : X,\n",
        "      \"y\" : y,\n",
        "  }\n",
        "\n",
        "  return data, col_names\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2644kRN7oDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kaggle_submission_csv(model, test_path, X, y, start=True):\n",
        "  '''\n",
        "  Args:\n",
        "  model(ML Model): The name of the machine learning model you trained on the data set\n",
        "  test_path(str): Path to the testing data\n",
        "  X(str): Name of the column containing all of the numbers(to identify testing data)\n",
        "  y(str): Name of the column containing the output of the testing data(corresponding to X)\n",
        "\n",
        "  Returns:\n",
        "  Nothing\n",
        "\n",
        "  It just converts it to a csv and done!    \n",
        "  '''\n",
        "\n",
        "  test = pd.read_csv(test_path)\n",
        "  print(test.shape)\n",
        "  columns = test.columns\n",
        "  predictions = (model.predict(test[columns]))\n",
        "  if start:\n",
        "    submit = pd.DataFrame({X : range(0, predictions.size+1), y:predictions})\n",
        "    submit.to_csv(\"submission.csv\", index=False)\n",
        "  else:\n",
        "    submit = pd.DataFrame({X : range(1, predictions.size+1), y:predictions})\n",
        "    submit.to_csv(\"submission.csv\", index=False)\n",
        "  print(\"Conversion Successful\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onCBeGKuBYsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize_data(X, y, column_index=0, task=\"scatter\", color=None):\n",
        "  '''\n",
        "  Args:\n",
        "    X: The x_axis you want(or first comparator for barplot)\n",
        "    y: The y_axis you want(or second compartor for barplot)\n",
        "    column_index (int) = The specific column from the X training data you are analyzing\n",
        "    task (string): The specific task you are trying to accomplish(line, scatter, bar, and histogram)\n",
        "    color (col_name): Distinguish different values(countries, flowers, etc.)\n",
        "    test_path (str): Path to the testing data\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "\n",
        "    But it shows a graph! \n",
        "  '''\n",
        "  \n",
        "  flag = False\n",
        "  if task == \"line\":\n",
        "    fig = px.line(x=X[:, column_index], y=y, color=color)\n",
        "    flag = True\n",
        "  elif task == \"scatter\":\n",
        "    fig = px.scatter(x=X[:, column_index], y=y)\n",
        "    flag = True\n",
        "  elif task == \"bar\":\n",
        "    fig = px.bar(x=X[:, column_index], y=y)\n",
        "    flag = True\n",
        "  elif task == \"hist\":\n",
        "    fig = px.histogram(x=X[:, column_index])\n",
        "    flag = True\n",
        "  elif task == \"compBP\":\n",
        "    sns.barplot(x=X, y=y)\n",
        "  \n",
        "  if flag:\n",
        "    fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSN-dT_CB8AU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_3d(x, y, z):\n",
        "  '''\n",
        "  Args:\n",
        "    x: numpy array with shape (n,)\n",
        "    y: numpy array with shape (n,)\n",
        "    z: numpy array with shape (n,)\n",
        "    \n",
        "  Returns:\n",
        "    Shows 3 dimensional PlotLy scatter plot\n",
        "  '''  \n",
        "  fig = px.scatter_3d(x=x, y=y, z=z)\n",
        "  fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1y4rOvSZnWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def regression_data(X_min=0, X_max=2, n_samples=100, n_features=1, noise='high'):\n",
        "  '''\n",
        "  Args:\n",
        "    X_min (int or list): if list, length of X_min should be n_features, specifies bounds for each feature\n",
        "                         if value specified is int, then X_min is same for all features\n",
        "    X_max (int or list): if list, length of X_max should be n_features, specifies bounds for each feature\n",
        "                         if value specified is int, then X_max is same for all features\n",
        "    n_samples (int): number of points to generate\n",
        "    n_features (int): number of features\n",
        "    noise (str): 3 possible levels ('high', 'medium', 'low')\n",
        "    \n",
        "  Returns:\n",
        "    (X_train, y_train): numpy array with train data\n",
        "    (X_test, y_test): numpy array with test data\n",
        "    if n_features is 1: returns scatter plot with data (PlotLy)\n",
        "    if n_features is 2: returns 3d scatter plot with data (PlotLy)\n",
        "    if n_features > 2: return 2d plot comparing first feature with target value\n",
        "  '''  \n",
        "  if type(X_max) == 'list':\n",
        "    data_range = np.array(X_max) - np.array(X_min)\n",
        "  else:\n",
        "    data_range = np.ones(n_features)*(X_max-X_min)\n",
        "    X_min = np.ones(n_features)*(X_min)\n",
        "\n",
        "  df = {}\n",
        "  df['X1'] = (data_range[0])*np.random.rand(n_samples) + X_min[0]\n",
        " \n",
        "  coef = 20*np.random.rand()-10\n",
        "  bias = (100)*np.random.rand()-100\n",
        "  if noise == 'high':\n",
        "    y = bias + coef*df['X1'] + 1*coef*data_range[0]*np.random.rand(n_samples)-X_min[0]\n",
        "\n",
        "  elif noise == 'medium':\n",
        "    y = bias + coef*df['X1'] + 0.7*coef*data_range[0]*np.random.rand(n_samples)-X_min[0]\n",
        "\n",
        "  elif noise == 'low':\n",
        "    y = bias + coef*df['X1'] + 0.5*coef*data_range[0]*np.random.rand(n_samples)-X_min[0]\n",
        "\n",
        "  if n_features > 1:\n",
        "    for i in range(n_features-1):\n",
        "      coef = 20*np.random.rand()-10\n",
        "      \n",
        "      df[f'X{i+2}'] = ((data_range[i+1])*np.random.rand(n_samples) + X_min[i+1])\n",
        "      y += coef*df[f'X{i+2}']\n",
        "  df['y'] = y\n",
        "  df = pd.DataFrame(df)\n",
        "\n",
        "  if n_features == 2:\n",
        "    plot_3d(df['X1'], df['X2'], df['y'])\n",
        "\n",
        "\n",
        "  if n_features != 2:\n",
        "    fig = px.scatter(x=df['X1'], y=y)\n",
        "    fig.show()\n",
        "  X_train, X_test, y_train, y_test = train_test_split(np.array(df.drop('y', axis=1, inplace=False)), np.array(df['y']), test_size=0.2)\n",
        "  return (X_train, y_train), (X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EbhrhjkzH7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classification_data(n_clusters=2, n_samples=100):\n",
        "  '''\n",
        "  Args:\n",
        "    n_clusters (int): number of clusters to generate\n",
        "    n_samples (int): number of points to generate in each cluster\n",
        "\n",
        "  Returns:\n",
        "    (X_train, y_train): numpy array with train data\n",
        "    (X_test, y_test): numpy array with test data\n",
        "    function call also displays 2d scatter plot with clusters\n",
        "  '''\n",
        "\n",
        "\n",
        "  distance = 50*(np.log(n_clusters))\n",
        "  data = {}\n",
        "  data['x'] = []\n",
        "  data['y'] = []\n",
        "  data['class'] = []\n",
        "  for i in range(n_clusters):\n",
        "    center1 = (100*((n_clusters/2)+2*n_clusters)*np.random.rand(), (100*((n_clusters/2)+2*n_clusters)*np.random.rand()))\n",
        "    x1 = np.random.uniform(center1[0], center1[0] + distance, size=(n_samples,))\n",
        "\n",
        "    for x in x1:\n",
        "      data['x'].append(x)\n",
        "    y1 = np.random.normal(center1[1], distance, size=(n_samples,)) \n",
        "\n",
        "    for y in y1:\n",
        "      data['y'].append(y)\n",
        "    \n",
        "    for label in np.ones(n_samples)*i:\n",
        "      data['class'].append(label)\n",
        "    \n",
        "  data = pd.DataFrame(data)\n",
        "  \n",
        "  data_2 = data.sample(frac=1).reset_index(drop=True)\n",
        "  arr = np.array(data_2)\n",
        "  data['class'] = [str(int(label)) for label in data['class']]\n",
        "  fig = px.scatter(data, x='x', y='y', color='class')\n",
        "  fig.show()\n",
        "  X_train, X_test, y_train, y_test = train_test_split(np.array(data.drop(['class'], axis=1, inplace=False)),\n",
        "                                                      np.array(data['class']), test_size=0.2)\n",
        "  return (X_train, y_train), (X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wygB8LKISSvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_images_from_dataframe(df, IMAGE_DIR, file_col='files', class_col='class', class_mode='raw',\n",
        "                               target_size=(100, 100), batch_size=16, shuffle=True, validation_split=0.2):\n",
        "  \n",
        "  '''\n",
        "  Args:\n",
        "    df (dataframe): one column with filenames, other columns signifying labelled classes\n",
        "    IMAGE_DIR (str): path to folder with all the images\n",
        "    file_col (str): name of column from df which contains the image file names\n",
        "    class_col (str or list): name of column with labels, if one-hot encoded labels, specify list with all column names\n",
        "    class_mode (str): 'raw' if labels are one-hot encoded\n",
        "                      'categorical' if labels are not one-hot encoded\n",
        "                      'binary' if there is one column with labels (column must contain strings ('black'/'white'), not int (0/1)!)\n",
        "    target_size (tuple): specifies image size, channels are automatically 3\n",
        "    batch_size (int): batch size to use while training\n",
        "    shuffle (bool): whether to shuffle or not\n",
        "    validation_split: fraction of total data used for testing\n",
        "\n",
        "  Returns:\n",
        "    train_generator: generator which yields images of specified size and normalized pixel values\n",
        "    test_generator: generator which yields images of specified size and normalized pixel values for testing\n",
        "  '''\n",
        "\n",
        "  img_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   validation_split=validation_split)\n",
        "\n",
        "  \n",
        "  train_generator = img_datagen.flow_from_dataframe(df,\n",
        "                                  directory=IMAGE_DIR,\n",
        "                                  x_col=file_col,\n",
        "                                  y_col=class_col,\n",
        "                                  target_size=target_size,\n",
        "                                  batch_size=batch_size,\n",
        "                                  shuffle=shuffle,\n",
        "                                  class_mode=class_mode,\n",
        "                                  subset='training')\n",
        "  \n",
        "  test_generator = img_datagen.flow_from_dataframe(df,\n",
        "                                  directory=IMAGE_DIR,\n",
        "                                  x_col=file_col,\n",
        "                                  y_col=class_col,\n",
        "                                  target_size=target_size,\n",
        "                                  batch_size=batch_size,\n",
        "                                  shuffle=shuffle,\n",
        "                                  class_mode=class_mode,\n",
        "                                  subset='validation')\n",
        "  \n",
        "  return train_generator, test_generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTm3x6bvtJV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_images_from_directory(IMAGE_DIR, target_size=(100, 100), class_mode='categorical', \n",
        "                               batch_size=16, shuffle=True, validation_split=0.2):\n",
        "  '''\n",
        "  Args:\n",
        "    IMAGE_DIR (str): path to folder with all the images\n",
        "    class_mode (str): 'binary' if there are only two subfolders\n",
        "                      'categorical' if images are stored under more than two subfolders\n",
        "    target_size (tuple): specifies image size, channels are automatically 3\n",
        "    batch_size (int): batch size to use while training\n",
        "    shuffle (bool): whether to shuffle or not\n",
        "    validation_split: fraction of total data used for testing\n",
        "\n",
        "  Returns:\n",
        "    train_generator: generator which yields images of specified size and normalized pixel values\n",
        "    test_generator: generator which yields images of specified size and normalized pixel values for testing\n",
        "  '''  \n",
        "\n",
        "  img_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   validation_split=validation_split)\n",
        "\n",
        "  \n",
        "  train_generator = img_datagen.flow_from_directory(\n",
        "                                  directory=IMAGE_DIR,\n",
        "                                  target_size=target_size,\n",
        "                                  batch_size=batch_size,\n",
        "                                  shuffle=shuffle,\n",
        "                                  class_mode=class_mode,\n",
        "                                  subset='training')\n",
        "  \n",
        "  test_generator = img_datagen.flow_from_directory(\n",
        "                                  directory=IMAGE_DIR,\n",
        "                                  target_size=target_size,\n",
        "                                  batch_size=batch_size,\n",
        "                                  shuffle=shuffle,\n",
        "                                  class_mode=class_mode,\n",
        "                                  subset='validation')\n",
        "  \n",
        "  return train_generator, test_generator"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}